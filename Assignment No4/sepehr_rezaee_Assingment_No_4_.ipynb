{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Sepehr Rezaee - 99242067"
      ],
      "metadata": {
        "id": "eUtB2psoR7Pk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWYSjM2ZR4Ja",
        "outputId": "f5795e89-d996-4a13-fd9b-530b15f8feee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.6.4-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Installing collected packages: snntorch\n",
            "Successfully installed snntorch-0.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torch snntorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dependencies"
      ],
      "metadata": {
        "id": "McNr94oCSE6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "myxUMHrDR9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the network architecture"
      ],
      "metadata": {
        "id": "l5SocE4ZSNoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STDPNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(STDPNetwork, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.lif1 = snn.Leaky(beta=0.1)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.lif2 = snn.Leaky(beta=0.1)\n",
        "\n",
        "        # Initialize mem_0 and mem_1 for both layers\n",
        "        self.mem_0_1 = torch.zeros(hidden_size)\n",
        "        self.mem_1_1 = torch.zeros(hidden_size)\n",
        "        self.mem_0_2 = torch.zeros(output_size)\n",
        "        self.mem_1_2 = torch.zeros(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x, self.mem_0_1 = self.lif1(x, self.mem_0_1)\n",
        "      x = self.fc2(x)\n",
        "      x, self.mem_0_2 = self.lif2(x, self.mem_0_2)\n",
        "      return x, self.mem_0_1, self.mem_0_2\n",
        "\n"
      ],
      "metadata": {
        "id": "xgaZA_LFSM9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the network"
      ],
      "metadata": {
        "id": "zP7u4didSaEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4\n",
        "hidden_size = 100\n",
        "output_size = 10\n",
        "net = STDPNetwork(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "ueLQ0JEQSTIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a loss function"
      ],
      "metadata": {
        "id": "EaMhLr-cSeqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "jHbcW0NPSgbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define an optimizer"
      ],
      "metadata": {
        "id": "QjMjnUHgSlWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "7iGRkAd5SmPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the STDP rule"
      ],
      "metadata": {
        "id": "w9wDNievca0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stdp(s_pre, s_post, w, a_plus, a_minus, tau_plus, tau_minus):\n",
        "    # Calculate the STDP update\n",
        "    dw = a_plus * s_pre * torch.exp(-s_post/tau_minus) - a_minus * s_post * torch.exp(-s_pre/tau_plus)\n",
        "    # Apply the update to the weights\n",
        "    w += dw\n",
        "    return w\n",
        "\n",
        "# Define the reward modulation function\n",
        "def reward_modulation(r, dw, beta):\n",
        "    # Modulate the STDP updates based on the reward\n",
        "    dw *= r * beta\n",
        "    return dw"
      ],
      "metadata": {
        "id": "itFVJmVRceba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the data"
      ],
      "metadata": {
        "id": "yZ1ifQrpTRiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([\n",
        "    [0, 0, 0, 0],  # 0\n",
        "    [0, 0, 0, 1],  # 1\n",
        "    [0, 0, 1, 0],  # 2\n",
        "    [0, 0, 1, 1],  # 3\n",
        "    [0, 1, 0, 0],  # 4\n",
        "    [0, 1, 0, 1],  # 5\n",
        "    [0, 1, 1, 0],  # 6\n",
        "    [0, 1, 1, 1],  # 7\n",
        "    [1, 0, 0, 0],  # 8\n",
        "    [1, 0, 0, 1],  # 9\n",
        "])\n",
        "\n",
        "targets = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ],
      "metadata": {
        "id": "T571ZlNcS_8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a DataLoader"
      ],
      "metadata": {
        "id": "TJHBl4AQTTt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(list(zip(inputs, targets)), batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "pK0dJpAtTfXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a training loop"
      ],
      "metadata": {
        "id": "cck5WjY3S7_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Convert the input data to float\n",
        "        input_data_float = inputs.float()\n",
        "\n",
        "        # Now use the float data for spike generation\n",
        "        input_spike_data = snn.spikegen.rate(input_data_float, time_var_input=True)\n",
        "\n",
        "        # If your input data is not time-varying\n",
        "        # Assume num_steps is the number of time steps you want\n",
        "        target_data_float = targets.float()\n",
        "        label_spike_data = snn.spikegen.rate(target_data_float, num_steps=4)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs, s_pre, s_post = net(input_spike_data)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, label_spike_data)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Apply STDP\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                dw = stdp(s_pre.detach(), s_post.detach(), param.data, a_plus=0.01, a_minus=0.01, tau_plus=20.0, tau_minus=20.0)  # Detach s_pre and s_post here\n",
        "                param.data = reward_modulation(r=1.0, dw=dw, beta=0.01)\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "id": "z8tvV-hlS4yT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "edbbf008-7322-42d0-bc2e-a514ca715017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-69f19f9c14d1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'weight'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_plus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_minus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_plus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_minus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Detach s_pre and s_post here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_modulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-a258892286d5>\u001b[0m in \u001b[0;36mstdp\u001b[0;34m(s_pre, s_post, w, a_plus, a_minus, tau_plus, tau_minus)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_minus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Calculate the STDP update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_plus\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_pre\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms_post\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau_minus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_minus\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_post\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms_pre\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau_plus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Apply the update to the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (10) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class STDPNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(STDPNetwork, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.lif1 = snn.Leaky(beta=0.1)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.lif2 = snn.Leaky(beta=0.1)\n",
        "\n",
        "        # Initialize mem_0 and mem_1 for both layers\n",
        "        self.mem_0_1 = torch.zeros(hidden_size)\n",
        "        self.mem_1_1 = torch.zeros(hidden_size)\n",
        "        self.mem_0_2 = torch.zeros(output_size)\n",
        "        self.mem_1_2 = torch.zeros(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x, self.mem_0_1 = self.lif1(x, self.mem_0_1)\n",
        "      x = self.fc2(x)\n",
        "      x, self.mem_0_2 = self.lif2(x, self.mem_0_2)\n",
        "      return x, self.mem_0_1, self.mem_0_2\n",
        "\n",
        "input_size = 4\n",
        "hidden_size = 100\n",
        "output_size = 10\n",
        "net = STDPNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "def stdp(s_pre, s_post, w, a_plus, a_minus, tau_plus, tau_minus):\n",
        "    # Calculate the STDP update\n",
        "    dw = a_plus * s_pre * torch.exp(-s_post/tau_minus) - a_minus * s_post * torch.exp(-s_pre/tau_plus)\n",
        "    # Apply the update to the weights\n",
        "    w += dw\n",
        "    return w\n",
        "\n",
        "# Define the reward modulation function\n",
        "def reward_modulation(r, dw, beta):\n",
        "    # Modulate the STDP updates based on the reward\n",
        "    dw *= r * beta\n",
        "    return dw\n",
        "\n",
        "inputs = torch.tensor([\n",
        "    [0, 0, 0, 0],  # 0\n",
        "    [0, 0, 0, 1],  # 1\n",
        "    [0, 0, 1, 0],  # 2\n",
        "    [0, 0, 1, 1],  # 3\n",
        "    [0, 1, 0, 0],  # 4\n",
        "    [0, 1, 0, 1],  # 5\n",
        "    [0, 1, 1, 0],  # 6\n",
        "    [0, 1, 1, 1],  # 7\n",
        "    [1, 0, 0, 0],  # 8\n",
        "    [1, 0, 0, 1],  # 9\n",
        "])\n",
        "\n",
        "targets = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "\n",
        "trainloader = DataLoader(list(zip(inputs, targets)), batch_size=1, shuffle=True)\n",
        "\n",
        "for epoch in range(100):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Convert the input data to float\n",
        "        input_data_float = inputs.float()\n",
        "\n",
        "        # Now use the float data for spike generation\n",
        "        input_spike_data = snn.spikegen.rate(input_data_float, time_var_input=True)\n",
        "\n",
        "        # If your input data is not time-varying\n",
        "        # Assume num_steps is the number of time steps you want\n",
        "        target_data_float = targets.float()\n",
        "        label_spike_data = snn.spikegen.rate(target_data_float, num_steps=4)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs, s_pre, s_post = net(input_spike_data)\n",
        "\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, label_spike_data)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Apply STDP\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                dw = stdp(s_pre.detach(), s_post.detach(), param.data, a_plus=0.01, a_minus=0.01, tau_plus=20.0, tau_minus=20.0)  # Detach s_pre and s_post here\n",
        "                param.data = reward_modulation(r=1.0, dw=dw, beta=0.01)\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "id": "4EdL-fTQRNTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch.spikeplot as splt\n",
        "import snntorch as snn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert the input data to float\n",
        "input_data_float = inputs.float()\n",
        "\n",
        "# Now use the float data for spike generation\n",
        "spike_data = snn.spikegen.rate(input_data_float, time_var_input=True)\n",
        "\n",
        "# If your input data is not time-varying\n",
        "# Assume num_steps is the number of time steps you want\n",
        "target_data_float = targets.float()\n",
        "spike_data = snn.spikegen.rate(target_data_float, num_steps=4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()  # create a new figure with a single Axes\n",
        "splt.raster(spike_data, ax)  # pass the Axes object to the raster() function\n",
        "plt.show()  # display the plot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bKt8fU9Me9qU",
        "outputId": "00c98273-3611-4694-881c-cff451b1aa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install brian2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwUTuVA6Priy",
        "outputId": "61ffabd9-6676-47ee-f866-8d8d1e2a3435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting brian2\n",
            "  Downloading Brian2-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.22.4)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from brian2) (0.29.35)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.11.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.0)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.2)\n",
            "Requirement already satisfied: setuptools>=24.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (67.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brian2) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7->brian2) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.2->brian2) (1.3.0)\n",
            "Installing collected packages: brian2\n",
            "Successfully installed brian2-2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from brian2 import *\n",
        "\n",
        "# Parameters\n",
        "num_inputs = 4\n",
        "num_outputs = 10\n",
        "duration = 100*ms\n",
        "\n",
        "# Range of weights\n",
        "weight_min = 0.0\n",
        "weight_max = 1.0\n",
        "\n",
        "# STDP learning parameters\n",
        "taupre = taupost = 20*ms\n",
        "wmax = 0.01\n",
        "Apre = 0.01\n",
        "Apost = -Apre*taupre/taupost*1.05\n",
        "\n",
        "# Neuron model\n",
        "eqs_neurons = '''\n",
        "dv/dt = (I-v) / (10*ms) : 1 (unless refractory)\n",
        "I : 1\n",
        "'''\n",
        "\n",
        "# Create neurons\n",
        "G = NeuronGroup(num_outputs, eqs_neurons, threshold='v>1', reset='v = 0', refractory=5*ms, method='exact')\n",
        "\n",
        "# Initialize weights\n",
        "weights = np.random.rand(num_inputs, num_outputs)*(weight_max - weight_min) + weight_min\n",
        "\n",
        "# Create synapses\n",
        "S = Synapses(G, G,\n",
        "             '''\n",
        "             w : 1\n",
        "             dapre/dt = -apre/taupre : 1 (event-driven)\n",
        "             dapost/dt = -apost/taupost : 1 (event-driven)\n",
        "             ''',\n",
        "             on_pre='''\n",
        "             v_post += w\n",
        "             apre += Apre\n",
        "             w = clip(w+apost, 0, wmax)\n",
        "             ''',\n",
        "             on_post='''\n",
        "             apost += Apost\n",
        "             w = clip(w+apre, 0, wmax)\n",
        "             ''')\n",
        "\n",
        "S.connect()\n",
        "S.w = weights.flatten()\n",
        "\n",
        "# Create input and run simulation\n",
        "input = np.random.randint(2, size=(num_inputs, int(duration/defaultclock.dt)))\n",
        "states = StateMonitor(G, 'v', record=True)\n",
        "spikes = SpikeMonitor(G)\n",
        "\n",
        "run(duration)\n",
        "\n",
        "# Plot results\n",
        "figure(figsize=(12,4))\n",
        "subplot(121)\n",
        "plot(spikes.t/ms, spikes.i, '.k')\n",
        "xlabel('Time (ms)')\n",
        "ylabel('Neuron index')\n",
        "subplot(122)\n",
        "plot(states.t/ms, states.v[0], '-k')\n",
        "xlabel('Time (ms)')\n",
        "ylabel('v')\n",
        "tight_layout()\n",
        "show()\n"
      ],
      "metadata": {
        "id": "t1SZJrJQgDaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "c51647bb-492f-4f40-ef8d-41cbff7df2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-71a37a1e9306>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Create input and run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brian2/groups/group.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, val, level)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Variable {name} is read-only.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Make the call X.var = ... equivalent to X.var[:] = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             var.get_addressable_value_with_unit(name, self).set_item(\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brian2/core/variables.py\u001b[0m in \u001b[0;36mset_item\u001b[0;34m(self, item, value, level, namespace)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# We do not want to go through code generation for runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_with_index_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                 self.set_with_expression_conditional(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brian2/core/base.py\u001b[0m in \u001b[0;36mdevice_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mdevice_override_decorated_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brian2/core/variables.py\u001b[0m in \u001b[0;36mset_with_index_array\u001b[0;34m(self, item, value, check_units)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                         \u001b[0;34mf\"{len(q)} != {len(indices)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                     )\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;31m# Allow some basic calculations directly on the ArrayView object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (40,) into shape (100,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4gFqcjDPjZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}